import requests
import os
import json
from azure.cognitiveservices.vision.customvision.prediction import CustomVisionPredictionClient
from msrest.authentication import ApiKeyCredentials

VISION_ENDPOINT = os.getenv("VISION_ENDPOINT")
VISION_KEY = os.getenv("VISION_KEY")
FACE_ENDPOINT = os.getenv("FACE_ENDPOINT")
FACE_KEY = os.getenv("FACE_KEY")

def detect_hand_side(image_path: str):
    url = f"{VISION_ENDPOINT}/computervision/imageanalysis:analyze"
    params = {
        "api-version": "2024-02-01",
        "features": "people"
    }
    headers = {
        "Ocp-Apim-Subscription-Key": VISION_KEY,
        "Content-Type": "application/octet-stream"
    }

    with open(image_path, "rb") as f:
        image_bytes = f.read()

    res = requests.post(url, params=params, headers=headers, data=image_bytes)
    res.raise_for_status()
    data = res.json()

    if not data.get("peopleResult", {}).get("values"):
        return None

    person = data["peopleResult"]["values"][0]
    person_box = person["boundingBox"]
    person_center_x = person_box["x"] + person_box["w"] / 2

    for part in person.get("bodyParts", []):
        if part["name"].lower() == "hand":
            hand_box = part["boundingBox"]
            hand_center_x = hand_box["x"] + hand_box["w"] / 2
            return hand_center_x > person_center_x  # True = right hand

    return None

def detect_expression(image_path: str, expected="happy"):
    url = f"{FACE_ENDPOINT}/face/v1.0/detect"
    params = {
        "returnFaceAttributes": "emotion",
        "detectionModel": "detection_01"
    }
    headers = {
        "Ocp-Apim-Subscription-Key": FACE_KEY,
        "Content-Type": "application/octet-stream"
    }

    with open(image_path, "rb") as f:
        image_bytes = f.read()

    res = requests.post(url, params=params, headers=headers, data=image_bytes)
    res.raise_for_status()
    faces = res.json()

    if not faces:
        return False

    emotion_scores = faces[0]["faceAttributes"]["emotion"]
    dominant_emotion = max(emotion_scores, key=emotion_scores.get)

    return dominant_emotion == expected

ENDPOINT = os.getenv("CUSTOM_VISION_ENDPOINT")
PREDICTION_KEY = os.getenv("CUSTOM_VISION_KEY")
PROJECT_ID = os.getenv("CUSTOM_VISION_PROJECT_ID")
PUBLISH_ITERATION_NAME = "face-expression-1"

def test_custom_vision():
    # 1. ì´ë¯¸ì§€ ê²½ë¡œ ì„¤ì • (í˜„ì¬ ìŠ¤í¬ë¦½íŠ¸ ìœ„ì¹˜ ê¸°ì¤€ìœ¼ë¡œ ìƒìœ„ í´ë”ì˜ test.jpg ì°¾ê¸°)
    current_dir = os.path.dirname(os.path.abspath(__file__))
    image_path = os.path.join(current_dir, "..", "test.jpg")

    print(f"ğŸ“‚ ì´ë¯¸ì§€ ê²½ë¡œ: {image_path}")

    if not os.path.exists(image_path):
        print("âŒ ë£¨íŠ¸ ê²½ë¡œì— 'test.jpg' íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤! íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
        return

    # 2. í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
    try:
        credentials = ApiKeyCredentials(in_headers={"Prediction-key": PREDICTION_KEY})
        predictor = CustomVisionPredictionClient(ENDPOINT, credentials)
    except Exception as e:
        print(f"âŒ í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return

    print("ğŸš€ Custom Visionì— ì´ë¯¸ì§€ ì „ì†¡ ì¤‘...")

    # 3. ì˜ˆì¸¡ ìš”ì²­ ë° ê²°ê³¼ ì¶œë ¥
    try:
        with open(image_path, "rb") as image_contents:
            results = predictor.classify_image(
                PROJECT_ID, 
                PUBLISH_ITERATION_NAME, 
                image_contents
            )

        print("\nâœ… ë¶„ì„ ê²°ê³¼:")
        print("-" * 30)
        
        # í™•ë¥ ìˆœ ì •ë ¬
        sorted_predictions = sorted(results.predictions, key=lambda x: x.probability, reverse=True)

        for prediction in sorted_predictions:
            # í™•ë¥ ì„ ë°±ë¶„ìœ¨ë¡œ í‘œì‹œ
            probability = prediction.probability * 100
            print(f"ğŸ·ï¸  {prediction.tag_name:<15}: {probability:.2f}%")

        print("-" * 30)
        
        # ê°€ì¥ ë†’ì€ í™•ë¥ ì˜ íƒœê·¸
        best_tag = sorted_predictions[0].tag_name
        best_prob = sorted_predictions[0].probability * 100
        print(f"ğŸ† ìµœì¢… íŒë‹¨: [{best_tag}] ({best_prob:.2f}%)")

    except Exception as e:
        print(f"âŒ ì˜ˆì¸¡ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        print("íŒ: Project ID, Key, Endpoint, Iteration Nameì´ ì •í™•í•œì§€ í™•ì¸í•´ë³´ì„¸ìš”.")

if __name__ == "__main__":
    
    # image = "test.jpg"

    # is_right_hand = detect_hand_side(image)
    # # expression_match = detect_expression(image, expected="happy")

    # print(json.dumps({
    #     "is_right_hand": is_right_hand,
    #     # "expression_match": expression_match
    # }, indent=2))

    test_custom_vision()