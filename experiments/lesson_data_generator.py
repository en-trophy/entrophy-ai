import sys
import os
import cv2
import mediapipe as mp
import json
import time
import numpy as np
import requests
import tempfile
from datetime import datetime

# í˜„ì¬ íŒŒì¼(answer_generator.py)ì˜ ë¶€ëª¨ì˜ ë¶€ëª¨ ë””ë ‰í† ë¦¬(í”„ë¡œì íŠ¸ ë£¨íŠ¸)ë¥¼ ê²½ë¡œì— ì¶”ê°€
sys.path.append(os.path.dirname(os.path.abspath(os.path.dirname(__file__))))

from app.services.feature_extractor import extract_feature_json
from app.services.expression_analyzation_service import analyze_expression_with_llm

API_BASE_URL = os.getenv("BACKEND_ENDPOINT", "https://equal-sign-backend-api-haejb5bdhnezc2c2.koreacentral-01.azurewebsites.net")
X_ADMIN_KEY = os.getenv("X_ADMIN_KEY", "equal_sign_media_upload")

# === ì„¤ì • ë° ì´ˆê¸°í™” ===
mp_holistic = mp.solutions.holistic
mp_drawing = mp.solutions.drawing_utils

class NumpyEncoder(json.JSONEncoder):
    def default(self, obj):
        if isinstance(obj, np.integer):
            return int(obj)
        elif isinstance(obj, np.floating):
            return float(obj)
        elif isinstance(obj, np.bool_):
            return bool(obj)
        elif isinstance(obj, np.ndarray):
            return obj.tolist()
        return super(NumpyEncoder, self).default(obj)

def generate_static_lesson():
    cap = cv2.VideoCapture(0)
    
    with mp_holistic.Holistic(
        min_detection_confidence=0.5,
        min_tracking_confidence=0.5) as holistic:
        
        print(">>> 3ì´ˆ ì¹´ìš´íŠ¸ë‹¤ìš´ ì‹œì‘!")
        start_time = time.time()
        
        captured_data = None
        final_image = None
        
        while cap.isOpened():
            ret, frame = cap.read()
            if not ret:
                break

            # ë¶„ì„ìš© ì›ë³¸ í”„ë ˆì„ (ì •ë°©í–¥)
            analysis_frame = frame.copy()
            # í™”ë©´ ì¶œë ¥ìš© í”„ë ˆì„ (ê±°ìš¸ëª¨ë“œ)
            display_frame = cv2.flip(frame, 1)

            elapsed = time.time() - start_time
            remaining = 3 - elapsed

            if remaining > 0:
                text = str(int(remaining) + 1)
                cv2.putText(display_frame, text, (300, 250),
                            cv2.FONT_HERSHEY_SIMPLEX, 7, (0, 255, 255), 10)
                cv2.imshow('Hand Capture', display_frame)
                cv2.waitKey(1)
                continue
            else:
                print(">>> ìº¡ì²˜ ë° ë¶„ì„ ì¤‘...")

                # 1. MediaPipe ë¶„ì„ì€ 'ì •ë°©í–¥(analysis_frame)'ìœ¼ë¡œ ìˆ˜í–‰
                image = cv2.cvtColor(analysis_frame, cv2.COLOR_BGR2RGB)
                image.flags.writeable = False
                results = holistic.process(image)

                # LLM ë¶„ì„ìš© ë°”ì´íŠ¸ ë³€í™˜ (ì •ë°©í–¥ ì‚¬ìš©)
                _, buffer = cv2.imencode('.jpg', analysis_frame)
                image_bytes = buffer.tobytes()

                expression = analyze_expression_with_llm(image_bytes)
                captured_data = extract_feature_json(results, expression)
                
                # 2. [ìˆ˜ì •ë¨] ì—…ë¡œë“œìš© ì´ë¯¸ì§€ëŠ” 'ê±°ìš¸ëª¨ë“œ'ë¡œ ì €ì¥
                final_image = cv2.flip(analysis_frame, 1) 

                cv2.putText(display_frame, "Captured!", (50, 250),
                            cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 255, 0), 3)
                cv2.imshow('Hand Capture', display_frame)
                cv2.waitKey(1000)
                break

    cap.release()
    cv2.destroyAllWindows()
    return captured_data, final_image

# ... (ì•ë¶€ë¶„ import ìƒëµ) ...

def generate_dynamic_lesson(duration_sec):
    cap = cv2.VideoCapture(0)
    
    # [í•µì‹¬] í•´ìƒë„ë¥¼ 640x480ìœ¼ë¡œ ê°•ì œ ë‹¤ìš´ì‚¬ì´ì§• (ìš©ëŸ‰ ë‹¤ì´ì–´íŠ¸)
    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
    
    current_dir = os.path.dirname(os.path.abspath(__file__))
    filename = f"sign_video_{int(time.time())}.mov"
    save_path = os.path.join(current_dir, filename)
    
    fourcc = cv2.VideoWriter_fourcc(*'avc1') 
    
    # ì‹¤ì œ ì„¤ì •ëœ í•´ìƒë„ í™•ì¸
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    fps = 30.0 # ê³ ì • 30fps
    
    out = cv2.VideoWriter(save_path, fourcc, fps, (width, height))

    frames_to_analyze = [] 
    
    print(f">>> ë…¹í™” í•´ìƒë„ ì„¤ì •: {width}x{height} (ìš©ëŸ‰ ìµœì í™” ëª¨ë“œ)")

    # [Phase 0] ì¹´ìš´íŠ¸ë‹¤ìš´
    start_time = time.time()
    while (time.time() - start_time) < 3:
        ret, frame = cap.read()
        if not ret: break
        display_frame = cv2.flip(frame, 1)
        remaining = 3 - (time.time() - start_time)
        cv2.putText(display_frame, str(int(remaining) + 1), (150, 200), # í…ìŠ¤íŠ¸ ìœ„ì¹˜ ì¡°ì •
                        cv2.FONT_HERSHEY_SIMPLEX, 4, (0, 255, 255), 5)
        cv2.imshow('Video Capture', display_frame)
        cv2.waitKey(1)

    # [Phase 1] ê³ ì† ë…¹í™”
    print(">>> ğŸ¥ ë…¹í™” ì‹œì‘!")
    record_start_time = time.time()
    last_capture_time = record_start_time - 1.0
    
    while cap.isOpened():
        ret, frame = cap.read()
        if not ret: break
        
        current_time = time.time()
        elapsed = current_time - record_start_time

        if elapsed > duration_sec:
            break

        out.write(cv2.flip(frame, 1))

        if (current_time - last_capture_time) >= 1.0:
            frames_to_analyze.append(frame.copy())
            last_capture_time = current_time

        display_frame = cv2.flip(frame, 1)
        cv2.putText(display_frame, "REC", (30, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)
        cv2.imshow('Video Capture', display_frame)
        
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break

    cap.release()
    out.release()
    cv2.destroyAllWindows()
    
    # [ìš©ëŸ‰ í™•ì¸ ë¡œê·¸ ì¶”ê°€]
    file_size_mb = os.path.getsize(save_path) / (1024 * 1024)
    print(f">>> ğŸ“ ìƒì„±ëœ íŒŒì¼ í¬ê¸°: {file_size_mb:.2f} MB")

    if file_size_mb > 10.0:
        print(">>> âš ï¸ ê²½ê³ : íŒŒì¼ í¬ê¸°ê°€ 10MBë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤. ì—…ë¡œë“œ ì‹¤íŒ¨ ê°€ëŠ¥ì„±ì´ ë†’ìŠµë‹ˆë‹¤.")

    # [Phase 2] AI ë¶„ì„ (ìƒëµ ì—†ì´ ì§„í–‰)
    print(f"\n>>> ğŸ§  ë…¹í™” ì™„ë£Œ. AI ë¶„ì„ ì‹œì‘ (ì´ {len(frames_to_analyze)}ì¥)...")
    
    captured_jsons = []
    
    with mp_holistic.Holistic(
        min_detection_confidence=0.5,
        min_tracking_confidence=0.5) as holistic:
        
        for idx, analysis_frame in enumerate(frames_to_analyze):
            # print(f"  ... Analyzing frame {idx + 1}")
            image_rgb = cv2.cvtColor(analysis_frame, cv2.COLOR_BGR2RGB)
            image_rgb.flags.writeable = False
            results = holistic.process(image_rgb)

            _, buffer = cv2.imencode('.jpg', analysis_frame)
            image_bytes = buffer.tobytes()

            expression = analyze_expression_with_llm(image_bytes)
            feature_json = extract_feature_json(results, expression)
            
            captured_jsons.append(feature_json)

    if os.path.exists(save_path) and os.path.getsize(save_path) > 0:
        print(f">>> âœ… ì˜ìƒ íŒŒì¼ ì¤€ë¹„ ì™„ë£Œ: {save_path}")
    else:
        return [], None
    
    return captured_jsons, save_path
def post_images(image):
    url = f"{API_BASE_URL}/api/storage/images"
    
    # OpenCV ì´ë¯¸ì§€ë¥¼ ë°”ì´íŠ¸ë¡œ ë³€í™˜
    _, img_encoded = cv2.imencode('.jpg', image)
    img_bytes = img_encoded.tobytes()
    
    # multipart/form-data ì„¤ì •
    files = {
        'file': ('image.jpg', img_bytes, 'image/jpeg')
    }
    headers = {'X-ADMIN-KEY': X_ADMIN_KEY}

    try:
        response = requests.post(url, headers=headers, files=files)
        response.raise_for_status()
        result = response.json()
        print(f"âœ… Image Upload Success: {result['uploadUrl']}")
        return result['uploadUrl']
    except Exception as e:
        print(f"âŒ Image Upload Failed: {e}")
        return None
    
def post_videos(video_path):
    url = f"{API_BASE_URL}/api/storage/videos"
    
    # [ìˆ˜ì • 3] Swagger ìš”ì²­ê³¼ ë™ì¼í•œ í—¤ë” êµ¬ì„±
    headers = {
        'X-ADMIN-KEY': X_ADMIN_KEY
    }
    
    print(f">>> ì—…ë¡œë“œ ì‹œë„: {video_path}")

    try:
        with open(video_path, 'rb') as f:
            # [ìˆ˜ì • 4] MIME íƒ€ì…ì„ Swaggerì™€ ë™ì¼í•˜ê²Œ 'video/quicktime'ìœ¼ë¡œ ì§€ì •
            # íŒŒì¼ëª…ë„ .movë¡œ ëª…ì‹œ
            files = {
                'file': ('video.mov', f, 'video/quicktime')
            }
            
            # timeoutì„ ë„‰ë„‰í•˜ê²Œ 60ì´ˆë¡œ ì„¤ì • (502 Timeout ë°©ì§€)
            response = requests.post(url, headers=headers, files=files, timeout=60)
            
            if response.status_code != 200:
                print(f"âŒ Server Error ({response.status_code}): {response.text}")
            
            response.raise_for_status()
            result = response.json()
            print(f"âœ… Video Upload Success: {result['uploadUrl']}")
            return result['uploadUrl']
    except requests.exceptions.Timeout:
        print("âŒ Upload Timeout: ì„œë²„ ì‘ë‹µì´ ë„ˆë¬´ ëŠ¦ìŠµë‹ˆë‹¤. íŒŒì¼ì´ ë„ˆë¬´ í¬ê±°ë‚˜ ë°±ì—”ë“œ ì²˜ë¦¬ê°€ ëŠë¦½ë‹ˆë‹¤.")
        return None
    except Exception as e:
        print(f"âŒ Video Upload Failed: {e}")
        return None
def post_lessons(category_id, title, sign_language, difficulty, type, mode, frame_number, image_url, video_url):
    url = f"{API_BASE_URL}/api/lessons"
    
    payload = {
        "categoryId": category_id,
        "title": title,
        "signLanguage": sign_language,
        "difficulty": difficulty,
        "type": type,
        "mode": mode,
        "imageUrl": image_url,
        "videoUrl": video_url,
        "frameNumber": frame_number
    }
    
    headers = {
        "Content-Type": "application/json",
    }

    try:
        response = requests.post(url, json=payload, headers=headers)
        response.raise_for_status()
        result = response.json()
        print(f"âœ… Lesson Created: ID {result['id']}")
        return result['id']
    except Exception as e:
        print(f"âŒ Lesson Creation Failed: {e}")
        return None

def post_answer_frames(lesson_id, seq, answer_frame):
    url = f"{API_BASE_URL}/api/lessons/{lesson_id}/answer-frames"
    
    payload = {
        "seq": seq,
        "hand": answer_frame, 
        "frameMeta": "meta_data_placeholder"
    }
    
    json_data = json.dumps(payload, cls=NumpyEncoder)
    
    headers = {
        "Content-Type": "application/json"
    }

    try:
        response = requests.post(url, data=json_data, headers=headers)
        response.raise_for_status()
        print(f"âœ… Answer Frame {seq} Uploaded")
    except Exception as e:
        print(f"âŒ Answer Frame Upload Failed: {e}")

def main():
    print("=== Sign Language Content Generator ===")
    try:
        category_id = int(input("Category ID : "))
        title = input("Title : ")
        sign_language = input("Sign Language (e.g. KSL, ASL) : ")
        difficulty = int(input("Difficulty (1-5) : "))
        is_word = input("Is Word? (y/n) : ").lower().startswith('y')
        type = "WORD" if is_word else "PHRASE"
        frame_number = int(input("Frame Number (Duration in sec) : "))
    except ValueError:
        print("Invalid Input.")
        return

    mode = None
    image_url = None
    video_url = None
    lesson_id = None

    if frame_number == 1:
        # ì •ì  ì´ë¯¸ì§€ ë¡œì§ (ìƒëµ - ê¸°ì¡´ ìœ ì§€)
        mode = "STATIC"
        hand_json, image = generate_static_lesson()
        if image is not None:
            image_url = post_images(image)
            if image_url:
                lesson_id = post_lessons(category_id, title, sign_language, difficulty, type, mode, frame_number, image_url, video_url)
                if lesson_id:
                    post_answer_frames(lesson_id, 1, hand_json)
    
    else:
        # ë™ì  ë¹„ë””ì˜¤ ë¡œì§
        mode = "DYNAMIC"
        hand_jsons, video_path = generate_dynamic_lesson(frame_number)
        
        if video_path and os.path.exists(video_path):
            video_url = post_videos(video_path)
            
            # [ìˆ˜ì • 3] íŒŒì¼ ì‚­ì œ ì½”ë“œ ì œê±° (íŒŒì¼ì´ ì‚¬ë¼ì§€ëŠ” ì›ì¸)
            # os.remove(video_path) 
            # print(">>> ì„ì‹œ íŒŒì¼ ì‚­ì œ ì™„ë£Œ")
            
            if video_url:
                lesson_id = post_lessons(category_id, title, sign_language, difficulty, type, mode, frame_number, image_url, video_url)
                
                if lesson_id:
                    for i, hand_json in enumerate(hand_jsons):
                        post_answer_frames(lesson_id, i + 1, hand_json)
            else:
                print(">>> âš ï¸ ë¹„ë””ì˜¤ ì—…ë¡œë“œ ì‹¤íŒ¨ë¡œ ë ˆìŠ¨ ìƒì„±ì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
        else:
            print(">>> âš ï¸ ë¹„ë””ì˜¤ íŒŒì¼ì´ ì—†ì–´ì„œ ì—…ë¡œë“œë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")

if __name__ == "__main__":
    main()